{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识表示：电影推荐实验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据和模型概览: \n",
    "\n",
    "- 数据提供（UserID，MovieID）组对，每个这样的组对，对应了一个 “标签”，帮助告诉模型用户和电影是否相似\n",
    "\n",
    "     * 当标签为一个数值时，我们可用模型来预测指定用户对指定电影的评分\n",
    "     * 当标签为二进制时，我们可用模型向用户推荐电影\n",
    "\n",
    "- 下图显示了*Object2Vec*模型可使用数据集提供的`(UserID, ItemID, Rating)` 样本数据，解决预测影片评分这个问题。在这里，评分是真实数值。当然，我们也可以把评分处理成二进制，方便后面的影片推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:middle\" src=\"image_ml_rating.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集\n",
    "\n",
    "我们将使用MovieLens上拥有10 万条数据的数据集： https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 应用场景\n",
    "\n",
    "- 任务 1：影片推荐模型训练（Object2Vec + 分类）\n",
    "- 任务 2：通过模型找到向量空间中的相似影片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在运行notebook之前\n",
    "\n",
    "- 请选择Python 3的kernel（核）\n",
    "- 请确保你安装了`jsonlines` 包，若还没有可以通过下面的指令安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv, jsonlines\n",
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据探索及准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据使用许可\n",
    "\n",
    "请仔细阅读 [data set description page](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt)相关描述，此数据仅可用于研究和教学用途，不可用于商业用途。\n",
    "有进一步问题请联系 GroupLens \\<grouplens-info@cs.umn.edu\\>。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 4808k  100 4808k    0     0  9283k      0 --:--:-- --:--:-- --:--:-- 9283k\n",
      "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: new name: replace k.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip\n",
    "rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 让我们首先创建一些用于数据探索和预处理的实用工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备些实用工具程序\n",
    "\n",
    "def load_csv_data(filename, delimiter, verbose=True):\n",
    "    \"\"\"\n",
    "    input: a file readable as csv and separated by a delimiter\n",
    "    and has format users - movies - ratings - etc\n",
    "    output: a list, where each row of the list is of the form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    \"\"\"\n",
    "    to_data_list = list()\n",
    "    users = list()\n",
    "    movies = list()\n",
    "    ratings = list()\n",
    "    unique_users = set()\n",
    "    unique_movies = set()\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            #if count!=0:\n",
    "            to_data_list.append({'in0':[int(row[0])], 'in1':[int(row[1])], 'label':float(row[2])})\n",
    "            users.append(row[0])\n",
    "            movies.append(row[1])\n",
    "            ratings.append(float(row[2]))\n",
    "            unique_users.add(row[0])\n",
    "            unique_movies.add(row[1])\n",
    "    if verbose:\n",
    "        print(\"In file {}, there are {} ratings\".format(filename, len(ratings)))\n",
    "        print(\"The ratings have mean: {}, median: {}, and variance: {}\".format(\n",
    "                                            round(np.mean(ratings), 2), \n",
    "                                            round(np.median(ratings), 2), \n",
    "                                            round(np.var(ratings), 2)))\n",
    "        print(\"There are {} unique users and {} unique movies\".format(len(unique_users), len(unique_movies)))\n",
    "    return to_data_list\n",
    "\n",
    "\n",
    "def csv_to_augmented_data_dict(filename, delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file that must be readable as csv and separated by delimiter (to make columns)\n",
    "    has format users - movies - ratings - etc\n",
    "    Output:\n",
    "      Users dictionary: keys as user ID's; each key corresponds to a list of movie ratings by that user\n",
    "      Movies dictionary: keys as movie ID's; each key corresponds a list of ratings of that movie by different users\n",
    "    \"\"\"\n",
    "    to_users_dict = dict() \n",
    "    to_movies_dict = dict()\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            #if count!=0:\n",
    "            if row[0] not in to_users_dict:\n",
    "                to_users_dict[row[0]] = [(row[1], row[2])]\n",
    "            else:\n",
    "                to_users_dict[row[0]].append((row[1], row[2]))\n",
    "            if row[1] not in to_movies_dict:\n",
    "                to_movies_dict[row[1]] = list(row[0])\n",
    "            else:\n",
    "                to_movies_dict[row[1]].append(row[0])\n",
    "    return to_users_dict, to_movies_dict\n",
    "\n",
    "\n",
    "def user_dict_to_data_list(user_dict):\n",
    "    # turn user_dict format to data list format (acceptable to the algorithm)\n",
    "    data_list = list()\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        for movie, rating in movie_rating_list:\n",
    "            data_list.append({'in0':[int(user)], 'in1':[int(movie)], 'label':float(rating)})\n",
    "    return data_list\n",
    "\n",
    "def divide_user_dicts(user_dict, sp_ratio_dict):\n",
    "    \"\"\"\n",
    "    Input: A user dictionary, a ration dictionary\n",
    "         - format of sp_ratio_dict = {'train':0.8, \"test\":0.2}\n",
    "    Output: \n",
    "        A dictionary of dictionaries, with key corresponding to key provided by sp_ratio_dict\n",
    "        and each key corresponds to a subdivded user dictionary\n",
    "    \"\"\"\n",
    "    ratios = [val for _, val in sp_ratio_dict.items()]\n",
    "    assert np.sum(ratios) == 1, \"the sampling ratios must sum to 1!\"\n",
    "    divided_dict = {}\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        sub_movies_ptr = 0\n",
    "        sub_movies_list = []\n",
    "        #movie_list, _ = zip(*movie_rating_list)\n",
    "        #print(movie_list)\n",
    "        for i, ratio in enumerate(ratios):\n",
    "            if i < len(ratios)-1:\n",
    "                sub_movies_ptr_end = sub_movies_ptr + int(len(movie_rating_list)*ratio)\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:sub_movies_ptr_end])\n",
    "                sub_movies_ptr = sub_movies_ptr_end\n",
    "            else:\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:])\n",
    "        for subset_name in sp_ratio_dict.keys():\n",
    "            if subset_name not in divided_dict:\n",
    "                divided_dict[subset_name] = {user: sub_movies_list.pop(0)}\n",
    "            else:\n",
    "                #access sub-dictionary\n",
    "                divided_dict[subset_name][user] = sub_movies_list.pop(0)\n",
    "    \n",
    "    return divided_dict\n",
    "\n",
    "def write_csv_to_jsonl(jsonl_fname, csv_fname, csv_delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file readable as csv and separated by delimiter (to make columns)\n",
    "        - has format users - movies - ratings - etc\n",
    "    Output: a jsonline file converted from the csv file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(jsonl_fname, mode='w') as writer:\n",
    "        with open(csv_fname, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=csv_delimiter)\n",
    "            for count, row in enumerate(reader):\n",
    "                #print(row)\n",
    "                #if count!=0:\n",
    "                writer.write({'in0':[int(row[0])], 'in1':[int(row[1])], 'label':float(row[2])})\n",
    "        print('Created {} jsonline file'.format(jsonl_fname))\n",
    "                    \n",
    "    \n",
    "def write_data_list_to_jsonl(data_list, to_fname):\n",
    "    \"\"\"\n",
    "    Input: a data list, where each row of the list is a Python dictionary taking form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    Output: save the list as a jsonline file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(to_fname, mode='w') as writer:\n",
    "        for row in data_list:\n",
    "            #print(row)\n",
    "            writer.write({'in0':row['in0'], 'in1':row['in1'], 'label':row['label']})\n",
    "    print(\"Created {} jsonline file\".format(to_fname))\n",
    "\n",
    "def data_list_to_inference_format(data_list, binarize=True, label_thres=3):\n",
    "    \"\"\"\n",
    "    Input: a data list\n",
    "    Output: test data and label, acceptable by SageMaker for inference\n",
    "    \"\"\"\n",
    "    data_ = [({\"in0\":row['in0'], 'in1':row['in1']}, row['label']) for row in data_list]\n",
    "    data, label = zip(*data_)\n",
    "    infer_data = {\"instances\":data}\n",
    "    if binarize:\n",
    "        label = get_binarized_label(list(label), label_thres)\n",
    "    return infer_data, label\n",
    "\n",
    "\n",
    "def get_binarized_label(data_list, thres):\n",
    "    \"\"\"\n",
    "    Input: data list\n",
    "    Output: a binarized data list for recommendation task\n",
    "    \"\"\"\n",
    "    for i, row in enumerate(data_list):\n",
    "        if type(row) is dict:\n",
    "            #if i < 10:\n",
    "                #print(row['label'])\n",
    "            if row['label'] > thres:\n",
    "                #print(row)\n",
    "                data_list[i]['label'] = 1\n",
    "            else:\n",
    "                data_list[i]['label'] = 0\n",
    "        else:\n",
    "            if row > thres:\n",
    "                data_list[i] = 1\n",
    "            else:\n",
    "                data_list[i] = 0\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file ml-100k/ua.base, there are 90570 ratings\n",
      "The ratings have mean: 3.52, median: 4.0, and variance: 1.27\n",
      "There are 943 unique users and 1680 unique movies\n",
      "In file ml-100k/ua.test, there are 9430 ratings\n",
      "The ratings have mean: 3.59, median: 4.0, and variance: 1.25\n",
      "There are 943 unique users and 1129 unique movies\n"
     ]
    }
   ],
   "source": [
    "## 导入数据并进行随机打乱处理\n",
    "prefix = 'ml-100k'\n",
    "train_path = os.path.join(prefix, 'ua.base')\n",
    "valid_path = os.path.join(prefix, 'ua.test')\n",
    "test_path = os.path.join(prefix, 'ub.test')\n",
    "\n",
    "train_data_list = load_csv_data(train_path, '\\t')\n",
    "random.shuffle(train_data_list)\n",
    "validation_data_list = load_csv_data(valid_path, '\\t')\n",
    "random.shuffle(validation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_users_dict, to_movies_dict = csv_to_augmented_data_dict(train_path, '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来，我们来做一些数据探索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, max, and median 'movies per user' is 10, 727, and 55.0\n",
      "The min, max, and median 'users per movie' is 1, 495, and 25.0\n",
      "In the training set\n",
      "There are 213 users with no more than 20 movies\n",
      "There are 12 movies with no more than 2 user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Users per movie')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 计算每个人看的电影数量的最小值，最大值，中位数\n",
    "movies_per_user = [len(val) for key, val in to_users_dict.items()]\n",
    "\n",
    "print(\"The min, max, and median 'movies per user' is {}, {}, and {}\".format(np.amin(movies_per_user),\n",
    "                                                                         np.amax(movies_per_user),\n",
    "                                                                         np.median(movies_per_user)))\n",
    "users_per_movie = [len(val) for key, val in to_movies_dict.items()]\n",
    "print(\"The min, max, and median 'users per movie' is {}, {}, and {}\".format(np.amin(users_per_movie),\n",
    "                                                                         np.amax(users_per_movie),\n",
    "                                                                          np.median(users_per_movie)))\n",
    "\n",
    "\n",
    "count = 0\n",
    "n_movies_lower_bound = 20\n",
    "for n_movies in movies_per_user:\n",
    "    if n_movies <= n_movies_lower_bound:\n",
    "        count += 1\n",
    "print(\"In the training set\")\n",
    "print('There are {} users with no more than {} movies'.format(count, n_movies_lower_bound))\n",
    "#\n",
    "count = 0\n",
    "n_users_lower_bound = 2\n",
    "for n_users in users_per_movie:\n",
    "    if n_users <= n_users_lower_bound:\n",
    "        count += 1\n",
    "print('There are {} movies with no more than {} user'.format(count, n_users_lower_bound))\n",
    "\n",
    "\n",
    "## 画图\n",
    "\n",
    "f = plt.figure(1)\n",
    "plt.hist(movies_per_user)\n",
    "plt.title(\"Movies per user\")\n",
    "##\n",
    "g = plt.figure(2)\n",
    "plt.hist(users_per_movie)\n",
    "plt.title(\"Users per movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 由于一个观众观看少于3个电影的情况占总数的比例非常小，可忽略不计，因此我们不会从数据集中删除这些数据；这个道理同样适用于电影被多少个观众看这个场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_r.jsonl jsonline file\n",
      "Created validation_r.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## 在本地保存训练数据集和验证数据集，供后面的评分预测任务（回归）使用\n",
    "\n",
    "write_data_list_to_jsonl(copy.deepcopy(train_data_list), 'train_r.jsonl')\n",
    "write_data_list_to_jsonl(copy.deepcopy(validation_data_list), 'validation_r.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_c.jsonl jsonline file\n",
      "Created validation_c.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## 在本地保存训练数据集和验证数据集，供后面的推荐任务（分类）使用\n",
    "\n",
    "### 将数据二进制化（1或0）\n",
    "\n",
    "train_c = get_binarized_label(copy.deepcopy(train_data_list), 3.0)\n",
    "valid_c = get_binarized_label(copy.deepcopy(validation_data_list), 3.0)\n",
    "\n",
    "write_data_list_to_jsonl(train_c, 'train_c.jsonl')\n",
    "write_data_list_to_jsonl(valid_c, 'validation_c.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们来检查下这两个分类的数据集在二进制化后，数据是否平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.5510213094843768 fraction of positive ratings in train_c.jsonl\n",
      "There are 0.5799575821845175 fraction of positive ratings in validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_c_label = [row['label'] for row in train_c]\n",
    "valid_c_label = [row['label'] for row in valid_c]\n",
    "\n",
    "print(\"There are {} fraction of positive ratings in train_c.jsonl\".format(\n",
    "                                np.count_nonzero(train_c_label)/len(train_c_label)))\n",
    "print(\"There are {} fraction of positive ratings in validation_c.jsonl\".format(\n",
    "                                np.sum(valid_c_label)/len(valid_c_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和推理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义一个用来存储数据和模型的 S3 存储桶，并将数据上传到这个 存储桶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import os\n",
    " \n",
    "bucket = 'movie-rec' # 填写你的S3桶的名称\n",
    "input_prefix = 'object2vec/movielens/input'\n",
    "output_prefix = 'object2vec/movielens/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据上传至S3并建立相关数据存储路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train data to s3://movie-rec/object2vec/movielens/input/rating/train/train_r.jsonl and defined input path\n",
      "Uploaded validation data to s3://movie-rec/object2vec/movielens/input/rating/validation/validation_r.jsonl and defined input path\n",
      "Trained model will be saved at s3://movie-rec/object2vec/movielens/output\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "input_paths = {}\n",
    "output_path = os.path.join('s3://', bucket, output_prefix)\n",
    "\n",
    "for data_name in ['train', 'validation']:\n",
    "    pre_key = os.path.join(input_prefix, 'rating', f'{data_name}')\n",
    "    fname = '{}_r.jsonl'.format(data_name)\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded {} data to {} and defined input path'.format(data_name, data_path))\n",
    "\n",
    "print('Trained model will be saved at', output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取Object2Vec的算法镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::130589633421:role/service-role/AmazonSageMaker-ExecutionRole-20200218T140233\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## 获取ObjectToVec算法的docker镜像\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'object2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推荐任务\n",
    "\n",
    "#### 下面，我们将展示如何通过Object2Vec，使用二进制评级标签来推荐电影。在这里，如果给定用户的电影评分标签将被进行二进制处理，标签评分为‘1’则表示应向用户推荐该影片，标签评分为 ‘0’则表示不应向用户推荐该影片。我们将调用二进制数据集预处理的函数进行评分标签的转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们将二进制的数据集上传至S3，再进行下一步的分类模型的训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data to s3://movie-rec/object2vec/movielens/input/recommendation/train/train_c.jsonl\n",
      "Uploaded data to s3://movie-rec/object2vec/movielens/input/recommendation/validation/validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_name in ['train', 'validation']:\n",
    "    fname = '{}_c.jsonl'.format(data_name)\n",
    "    pre_key = os.path.join(input_prefix, 'recommendation', f\"{data_name}\")\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded data to {}'.format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 我们刚才已经获取了算法的镜像，现在可以开始训练模型了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "hyperparameters_c = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3, \n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_cnn_filter_width\": 3,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 2048,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 2048,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"softmax\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 05:17:54 Starting - Starting the training job...\n",
      "2020-05-22 05:17:57 Starting - Launching requested ML instances.........\n",
      "2020-05-22 05:19:39 Starting - Preparing the instances for training......\n",
      "2020-05-22 05:20:51 Downloading - Downloading input data...\n",
      "2020-05-22 05:21:03 Training - Downloading the training image......\n",
      "2020-05-22 05:22:12 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': 3, u'epochs': 30, u'mlp_dim': 512, u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': 2, u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': 300, u'tied_token_embedding_weight': u'false', u'learning_rate': 0.0004, u'enc1_cnn_filter_width': 3, u'negative_sampling_rate': 0, u'enc0_network': u'hcnn', u'enc1_layers': u'auto', u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': 32, u'enc1_pretrained_embedding_file': u'', u'num_classes': 2, u'_num_gpus': u'auto', u'enc1_token_embedding_dim': 300, u'mlp_activation': u'linear', u'enc1_network': u'enc0', u'_kvstore': u'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'mini_batch_size': u'2048', u'enc0_token_embedding_dim': u'300', u'enc1_network': u'pooled_embedding', u'early_stopping_tolerance': u'0.01', u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'enc1_cnn_filter_width': u'3', u'learning_rate': u'0.001', u'bucket_width': u'0', u'enc_dim': u'2048', u'enc0_layers': u'auto', u'enc0_max_seq_len': u'1', u'num_classes': u'2', u'_num_gpus': u'auto', u'mlp_activation': u'relu', u'enc1_token_embedding_dim': u'300', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Final configuration: {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] use bucketing: False\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:15 INFO 140234599638848] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Source words: 90570\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Target words: 90570\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Bucket of (1, 1) : 90570 samples in 44 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Replicating 1590 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Bucket batch sizes: [BucketBatchSize(batch_size=2048, average_words_per_batch=2048)]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] create_iter params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] use bucketing: False\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Source words: 9430\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Target words: 9430\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Bucket of (1, 1) : 9430 samples in 4 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Replicating 810 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Config: {'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'token_embedding_storage_type': 'dense', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'negative_sampling_rate': 0, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'tied_token_embedding_weight': False, 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': 1, 'is_train': True, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Creating new state\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] params {u'comparator_list': u'hadamard, concat, abs_diff', u'enc0_vocab_file': u'', u'output_layer': u'softmax', u'enc0_cnn_filter_width': u'3', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0_freeze_pretrained_embedding': u'true', u'mlp_layers': u'1', u'_num_kv_servers': u'auto', u'weight_decay': 0, u'enc0_pretrained_embedding_file': u'', u'enc0_max_seq_len': u'1', u'token_embedding_storage_type': u'dense', u'enc0_token_embedding_dim': u'300', u'tied_token_embedding_weight': u'false', u'learning_rate': u'0.001', u'enc1_cnn_filter_width': u'3', u'negative_sampling_rate': 0, u'enc0_network': u'pooled_embedding', u'enc1_layers': u'auto', u'early_stopping_patience': u'3', u'optimizer': u'adam', u'enc1_max_seq_len': u'1', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', 'default_bucket_key': (1, 1), u'enc1_vocab_file': u'', u'enc1_freeze_pretrained_embedding': u'true', u'enc0_layers': u'auto', u'mini_batch_size': u'2048', u'enc1_pretrained_embedding_file': u'', u'num_classes': u'2', u'_num_gpus': u'auto', u'enc1_token_embedding_dim': u'300', u'mlp_activation': u'relu', u'enc1_network': u'pooled_embedding', u'_kvstore': u'device', u'enc1_vocab_size': u'1684', u'enc0_vocab_size': u'944'}\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] nvidia-smi took: 0.100718975067 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Create Store: device\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 WARNING 140234599638848] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x2048                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x2048                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           2048                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       2048                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   2048                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x2048                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x2048                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           2048                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       2048                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   2048                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           2048                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     8192                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             1024                    8389632     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             1024                    0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   1024                    0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        2                       2050        dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 8391682\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] data_shapes [DataDesc[source,(2048, 1),<type 'numpy.float32'>,NTC], DataDesc[target,(2048, 1),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] label_shapes [DataDesc[out_layer_label,(2048,),<type 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:18 INFO 140234599638848] Initialized BucketingPlus Module\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/22/2020 05:22:24 INFO 140234599638848] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:24 INFO 140234599638848] all params:['output_layer_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_bias', 'embed_1_weight', 'embed_0_weight']\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 5587.174892425537, \"sum\": 5587.174892425537, \"min\": 5587.174892425537}}, \"EndTime\": 1590124944.461489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124935.950809}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1590124944.461673, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124944.461613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:28 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:28 INFO 140234599638848] Completed Epoch: 0, time taken: 0:00:04.207865\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:28 INFO 140234599638848] Epoch 0 Training metrics:   perplexity: 1.845 cross_entropy: 0.612 accuracy: 0.663 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:28 INFO 140234599638848] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.612271308899\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:28 INFO 140234599638848] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.663161892361\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] Epoch 0 Validation metrics: perplexity: 1.787 cross_entropy: 0.580 accuracy: 0.695 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.580398201942\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.69541015625\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.30684471130371094, \"sum\": 0.30684471130371094, \"min\": 0.30684471130371094}, \"update.time\": {\"count\": 1, \"max\": 4330.833911895752, \"sum\": 4330.833911895752, \"min\": 4330.833911895752}}, \"EndTime\": 1590124949.014284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124944.461563}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Total Records Seen\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1590124949.014577, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1590124944.68343}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:29 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21277.7501373 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] Completed Epoch: 1, time taken: 0:00:04.274716\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] Epoch 1 Training metrics:   perplexity: 1.722 cross_entropy: 0.543 accuracy: 0.721 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.543392349614\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.720768229167\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] Epoch 1 Validation metrics: perplexity: 1.772 cross_entropy: 0.572 accuracy: 0.700 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.572257637978\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.699609375\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 3.6249160766601562, \"sum\": 3.6249160766601562, \"min\": 3.6249160766601562}, \"update.time\": {\"count\": 1, \"max\": 4397.960901260376, \"sum\": 4397.960901260376, \"min\": 4397.960901260376}}, \"EndTime\": 1590124953.428839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124949.014368}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}, \"Total Records Seen\": {\"count\": 1, \"max\": 184320, \"sum\": 184320.0, \"min\": 184320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1590124953.429152, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1590124949.030855}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:33 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=20952.6453405 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] Completed Epoch: 2, time taken: 0:00:04.177321\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] Epoch 2 Training metrics:   perplexity: 1.653 cross_entropy: 0.503 accuracy: 0.751 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.502849800057\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.750748697917\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] Epoch 2 Validation metrics: perplexity: 1.815 cross_entropy: 0.596 accuracy: 0.696 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.595916318893\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.6958984375\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.028133392333984375, \"sum\": 0.028133392333984375, \"min\": 0.028133392333984375}, \"update.time\": {\"count\": 1, \"max\": 4305.253982543945, \"sum\": 4305.253982543945, \"min\": 4305.253982543945}}, \"EndTime\": 1590124957.825689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124953.428923}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 135, \"sum\": 135.0, \"min\": 135}, \"Total Records Seen\": {\"count\": 1, \"max\": 276480, \"sum\": 276480.0, \"min\": 276480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1590124957.825987, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1590124953.520402}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:37 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21403.7972768 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] Completed Epoch: 3, time taken: 0:00:04.196216\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] Epoch 3 Training metrics:   perplexity: 1.386 cross_entropy: 0.327 accuracy: 0.864 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.326586329937\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.864040798611\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] Epoch 3 Validation metrics: perplexity: 2.125 cross_entropy: 0.754 accuracy: 0.674 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.753706336021\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.67392578125\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] patience losses: [0.5803982019424438, 0.5722576379776001, 0.5959163188934327]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] min patience losses: 0.572257637978\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] current loss: 0.753706336021\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] absolute loss difference: 0.181448698044\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4780292510986328, \"sum\": 0.4780292510986328, \"min\": 0.4780292510986328}, \"update.time\": {\"count\": 1, \"max\": 4316.3161277771, \"sum\": 4316.3161277771, \"min\": 4316.3161277771}}, \"EndTime\": 1590124962.147561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124957.825794}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 180, \"sum\": 180.0, \"min\": 180}, \"Total Records Seen\": {\"count\": 1, \"max\": 368640, \"sum\": 368640.0, \"min\": 368640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1590124962.147809, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1590124957.831222}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:42 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21349.6079822 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] Completed Epoch: 4, time taken: 0:00:04.216339\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] Epoch 4 Training metrics:   perplexity: 1.079 cross_entropy: 0.076 accuracy: 0.980 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.0764139492479\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.979568142361\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] Epoch 4 Validation metrics: perplexity: 2.601 cross_entropy: 0.956 accuracy: 0.693 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.955849802494\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.693359375\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] patience losses: [0.5722576379776001, 0.5959163188934327, 0.7537063360214233]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] min patience losses: 0.572257637978\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] current loss: 0.955849802494\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] absolute loss difference: 0.383592164516\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.41103363037109375, \"sum\": 0.41103363037109375, \"min\": 0.41103363037109375}, \"update.time\": {\"count\": 1, \"max\": 4336.849927902222, \"sum\": 4336.849927902222, \"min\": 4336.849927902222}}, \"EndTime\": 1590124966.488567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124962.147642}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 225, \"sum\": 225.0, \"min\": 225}, \"Total Records Seen\": {\"count\": 1, \"max\": 460800, \"sum\": 460800.0, \"min\": 460800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1590124966.488831, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1590124962.151694}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:46 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21248.3643302 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] Completed Epoch: 5, time taken: 0:00:04.217042\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] Epoch 5 Training metrics:   perplexity: 1.013 cross_entropy: 0.013 accuracy: 0.999 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.0129391893434\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.99873046875\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] Epoch 5 Validation metrics: perplexity: 2.881 cross_entropy: 1.058 accuracy: 0.693 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=1.05796439648\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.693359375\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] patience losses: [0.5959163188934327, 0.7537063360214233, 0.955849802494049]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] min patience losses: 0.595916318893\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] current loss: 1.05796439648\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] absolute loss difference: 0.462048077583\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4839897155761719, \"sum\": 0.4839897155761719, \"min\": 0.4839897155761719}, \"update.time\": {\"count\": 1, \"max\": 4341.465950012207, \"sum\": 4341.465950012207, \"min\": 4341.465950012207}}, \"EndTime\": 1590124970.834307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124966.488649}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 270, \"sum\": 270.0, \"min\": 270}, \"Total Records Seen\": {\"count\": 1, \"max\": 552960, \"sum\": 552960.0, \"min\": 552960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1590124970.834576, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1590124966.492817}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:50 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21225.7895741 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Completed Epoch: 6, time taken: 0:00:04.213603\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Epoch 6 Training metrics:   perplexity: 1.003 cross_entropy: 0.003 accuracy: 1.000 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.00281973523864\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=0.999956597222\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Epoch 6 Validation metrics: perplexity: 3.093 cross_entropy: 1.129 accuracy: 0.697 \u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=1.12903690338\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.69716796875\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] **************\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] patience losses: [0.7537063360214233, 0.955849802494049, 1.0579643964767456]\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] min patience losses: 0.753706336021\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] current loss: 1.12903690338\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] absolute loss difference: 0.37533056736\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.6358623504638672, \"sum\": 0.6358623504638672, \"min\": 0.6358623504638672}, \"update.time\": {\"count\": 1, \"max\": 4335.0830078125, \"sum\": 4335.0830078125, \"min\": 4335.0830078125}}, \"EndTime\": 1590124975.173533, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124970.83441}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 315, \"sum\": 315.0, \"min\": 315}, \"Total Records Seen\": {\"count\": 1, \"max\": 645120, \"sum\": 645120.0, \"min\": 645120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1590124975.173875, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1590124970.838428}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] #throughput_metric: host=algo-1, train throughput=21256.6569719 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 WARNING 140234599638848] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Best model based on epoch 1. Best loss: 0.572\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.9849071502685547, \"sum\": 0.9849071502685547, \"min\": 0.9849071502685547}}, \"EndTime\": 1590124975.175219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124975.173626}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Saved checkpoint to \"/tmp/tmp9pTVpu/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2020 05:22:55 INFO 140234599638848] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 39875.43702125549, \"sum\": 39875.43702125549, \"min\": 39875.43702125549}, \"model.serialize.time\": {\"count\": 1, \"max\": 228.33991050720215, \"sum\": 228.33991050720215, \"min\": 228.33991050720215}, \"setuptime\": {\"count\": 1, \"max\": 377.63381004333496, \"sum\": 377.63381004333496, \"min\": 377.63381004333496}}, \"EndTime\": 1590124975.408728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1590124975.175271}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-22 05:22:58 Uploading - Uploading generated training model\n",
      "2020-05-22 05:23:30 Completed - Training job completed\n",
      "Training seconds: 159\n",
      "Billable seconds: 159\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "## 获取推算器\n",
    "classifier = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.p2.xlarge',\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "## 代入设置好的高参数\n",
    "classifier.set_hyperparameters(**hyperparameters_c)\n",
    "\n",
    "## 训练，调整，测试模型\n",
    "classifier.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练完后，我们来用测试数据集再来验证一遍模型的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "classification_model = classifier.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json')\n",
    "\n",
    "predictor = classification_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c_data, valid_c_label = data_list_to_inference_format(copy.deepcopy(validation_data_list), \n",
    "                                                            label_thres=3, binarize=True)\n",
    "predictions = predictor.predict(valid_c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the binarized validation set is 0.701\n"
     ]
    }
   ],
   "source": [
    "def get_class_accuracy(res, labels, thres):\n",
    "    if type(res) is dict:\n",
    "        res = res['predictions']\n",
    "    assert len(res)==len(labels), 'result and label length mismatch!'\n",
    "    accuracy = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            if row['scores'][1] > thres:\n",
    "                prediction = 1\n",
    "            else: \n",
    "                prediction = 0\n",
    "            if label > thres:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            accuracy += 1 - (prediction - label)**2\n",
    "    return accuracy / float(len(res))\n",
    "\n",
    "print(\"The accuracy on the binarized validation set is %.3f\" %get_class_accuracy(predictions, valid_c_label, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试数据集里测出来的模型准确率应该在0.7左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行电影推荐\n",
    "\n",
    "由于 *Object2Vec* 在训练过程中将用户ID和影片ID转换为向量内容。训练后，它分别在左侧和右侧编码器中获取用户和电影的向量。简单来讲，算法将这些内容和关系调整为向量表示，以便于接下来进行监督学习任务。因为对于特定用户而言，类似的电影应该具有类似的评分，我们期望类似的电影在向量空间中处于 **相近** 的位置。\n",
    "\n",
    "下面，我们将演示如何在所有影片ID中找到指定影片ID的最邻近（欧式距离）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_embedding_dict(movie_ids, trained_model):\n",
    "    input_instances = list()\n",
    "    for s_id in movie_ids:\n",
    "        input_instances.append({'in1': [s_id]})\n",
    "    data = {'instances': input_instances}\n",
    "    movie_embeddings = trained_model.predict(data)\n",
    "    embedding_dict = {}\n",
    "    for s_id, row in zip(movie_ids, movie_embeddings['predictions']):\n",
    "        embedding_dict[s_id] = np.array(row['embeddings'])\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "def load_movie_id_name_map(item_file):\n",
    "    movieID_name_map = {}\n",
    "    with open(item_file, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        for row in f.readlines():\n",
    "            row = row.strip()\n",
    "            split = row.split('|')\n",
    "            movie_id = split[0]\n",
    "            movie_name = split[1]\n",
    "            sparse_tags = split[-19:]\n",
    "            movieID_name_map[int(movie_id)] = movie_name \n",
    "    return movieID_name_map\n",
    "\n",
    "            \n",
    "def get_nn_of_movie(movie_id, candidate_movie_ids, embedding_dict):\n",
    "    movie_emb = embedding_dict[movie_id]\n",
    "    min_dist = float('Inf')\n",
    "    best_id = candidate_movie_ids[0]\n",
    "    for idx, m_id in enumerate(candidate_movie_ids):\n",
    "        candidate_emb = embedding_dict[m_id]\n",
    "        curr_dist = np.linalg.norm(candidate_emb - movie_emb)\n",
    "        if curr_dist < min_dist:\n",
    "            best_id = m_id\n",
    "            min_dist = curr_dist\n",
    "    return best_id, min_dist\n",
    "\n",
    "\n",
    "def get_unique_movie_ids(data_list):\n",
    "    unique_movie_ids = set()\n",
    "    for row in data_list:\n",
    "        unique_movie_ids.add(row['in1'][0])\n",
    "    return list(unique_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = load_csv_data(train_path, '\\t', verbose=False)\n",
    "unique_movie_ids = get_unique_movie_ids(train_data_list)\n",
    "embedding_dict = get_movie_embedding_dict(unique_movie_ids, predictor)\n",
    "candidate_movie_ids = unique_movie_ids.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用下面的脚本，你可以查看与数据集中任何影片最接近的影片。比如，在向量空间中找到最接近的电影 `终结者（1984）` 是 `侏罗纪公园 (1988)`  。\n",
    "\n",
    "- 只需输入要检索的电影 ID ，例如，`终结者（1984）` 影片 ID 为 195；你可以在 `u.item` 文件中找到影片名称和 ID的成对组合\n",
    "- 请注意，由于模型初始化的随机性，你的运行结果可能会有所不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "movie_id_to_examine = 195 # 填入你想要测试的电影ID号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest movie to Terminator, The (1984) in the embedding space is Jurassic Park (1993)\n"
     ]
    }
   ],
   "source": [
    "candidate_movie_ids.remove(movie_id_to_examine)\n",
    "best_id, min_dist = get_nn_of_movie(movie_id_to_examine, candidate_movie_ids, embedding_dict)\n",
    "movieID_name_map = load_movie_id_name_map('ml-100k/u.item')\n",
    "print('The closest movie to {} in the embedding space is {}'.format(movieID_name_map[movie_id_to_examine],\n",
    "                                                                  movieID_name_map[best_id]))\n",
    "candidate_movie_ids.append(movie_id_to_examine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学习完毕后，建议删除用于托管模型的终端节点，避免云资源的浪费"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 清理终端节点\n",
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
